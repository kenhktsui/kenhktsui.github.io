<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h3><strong>AI/Machine Learning 2022 Review and 2023 Outlook — A Practitioner’s Perspective</strong></h3> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*U3c5dUmEb1769yezHDLE-g.jpeg"></figure> <p>In the last day of 2022, it’s always a great opportunity to summarise what had happened and to look ahead to how AI will further evolve. Of course, what I mention below is not exhaustive and is more of my personal opinion. I intend not to spend a lot time writing this article because it reflects the big picture I have in mind, and also a snapshot of my view.</p> <p>2022 has been an exciting year of AI, where we see some critical and influential achievements in AI, including but not limited to:</p> <ul> <li>release of some mega size datasets like LAION-5B, that is critical to the success of Stable Diffusion</li> <li>Stability AI releasing open-source Stable Diffusion models, which disrupts art &amp; design industry, and multiple variants of fine-tuned models were developed upon it</li> <li>BLOOM, an open-source large language model whose development is boostrapped by HuggingFace, GENCI and IDRIS</li> <li>launch of OpenAI’s ChatGPT, which leads to countless use case in multiple domains, from writing a joke/ a letter/ a contract/ code/ book to asking for technical/financial/ life advice</li> </ul> <p>From the perspective of an applied machine learning researcher and practitioner, 2022 has shown that:</p> <p><strong>From Large Language Model to AGI</strong></p> <ul> <li>we are much closer to AGI (artificial general intelligence) than we thought (well there is still dispute but we can see large language model could pass Turing test in multiple settings. Simply the definition of AGI, and its testing worth a long article)</li> <li>way to AGI may be more about aligning large model behaviour with human behaviour as we see the difference betweenOpenAI’s GPT3.5 and ChatGPT</li> <li>scaling law in language model continues to hold true</li> <li>large language model no longer concerns about overfitting, as it memorises all knowledge possibly collected in the universe</li> <li>transformer can handle very long sequences, with more GPUs</li> </ul> <p><strong>Image Generation</strong></p> <ul> <li>text is very important to control image generation, much better than predetermined classes</li> <li>diffusion model becomes the de facto image generation architecture</li> </ul> <p><strong>Open-source Collaboration</strong></p> <ul><li>open-source collaboration is a successful working model for AI</li></ul> <p>I am very excited about what will happen in 2023. Below are my predictions for 2023:</p> <p><strong>From Large Language Model to AGI</strong></p> <ul> <li>larger language model (which does not need prediction, as we see GPT-4 is coming)</li> <li>effort to understand why large language model is so good at zero shot learning/ look for smaller model size without performance degradation</li> <li>continuous effort to align model behaviour with human behaviour via Reinforcement Learning</li> <li>giving large model’s access to physical world</li> <li>development of rigorous AI reasoning and causation test and dataset</li> <li>more multimodal attempt</li> </ul> <p><strong>AI Safety</strong></p> <ul><li>more advanced detection of unfair use of large model, as generative model becomes more advanced</li></ul> <p><strong>Open-source Collaboration</strong></p> <ul><li>development of open-source ChatGPT-like system (which is already happening)</li></ul> <p>As ML practitioners, given the rise of large language model, there are a lot of opportunities ahead:</p> <ul> <li>have a productivity boost with ChatGPT-like system</li> <li>do more creative and deeper work that can’t be found in ChatGPT-like system, better understanding of model behaviour, more rigorous scientific process and less on coding</li> <li>produce specialised/ small version of ChatGPT-like system that can be deployed in private cloud</li> <li>leverage ChatGPT-like system as a human-machine interface and a workflow orchestrator</li> <li>building inputs for ChatGPT-like system</li> <li>participate into open-source collaboration</li> <li>be ready to finetune large model whose weight can’t be fit in 1 GPU</li> </ul> <p>Again, all the above are my personal views and its not meant to be a scientific and complete review, as I do not spend more than two hours writing this.</p> <p>Last but not least, wish everyone a happy new year!</p> <p>Note 1 : Opinions expressed are solely my own and do not express the views or opinions of my employer.</p> <p>Note 2: The article is not generated by ChatGPT nor curated by it.</p> <p>Note 3: Machine learning and AI are used interchangeably in this article because the recent advancement in AI is mostly fuelled by machine learning.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9d1b34c0a21f" width="1" height="1" alt=""></p> </body></html>