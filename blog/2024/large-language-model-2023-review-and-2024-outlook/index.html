<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>TLDR: 2023 is <strong>The Year of Open Source LLM</strong>; 2024 will be <strong>The Year of SLM and Synthetic Data</strong></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yFC890eaMALKrzqI8tVMQg.jpeg"><figcaption>Mount Fuji by Author</figcaption></figure> <p>What a year in 2023! 2023 kickstarted with everyone including executives talking about ChatGPT at the beginning of the year. Given the realisation of imperfect yet unlimited potential (research and business) of LLM, the LLM space has drawn a lot of resources from elsewhere. LLM space has been growing exponentially, unlike the rest of the world.</p> <p>To explain why I feel LLM space is exponential, one anecdote is I did an hour sharing on LLM back in Feb 2023 focusing on the language model scaling law, supervised finetuning (SFT) and reinforcement learning with human feedback (RLHF), and when I looked back the slide now, it felt like they are no longer (so) relevant.</p> <p>As a open source contributor who had the opportunity to work with some brilliant independent researchers to build dataset/ train model; and also as a ML engineer who applies LLM in production and faces new production challenges, I have been with LLM more than ever.</p> <p>Same as <a href="https://medium.com/@kentsui/ai-machine-learning-2022-review-and-2023-outlook-a-practitioners-perspective-9d1b34c0a21f" rel="external nofollow noopener" target="_blank">last year</a>, I made an attempt to summarise what had come into my attention in 2023, and write an article in a day without the help of any LLM (You can tell from my writing) as I trust my first instinct without rethinking can bring me the most memorable moments in 2023.</p> <p>Despite reading &gt; 200+ paper, I might still miss quite a lot as an average person trying to catch an exponential trend, so feedbacks welcomed.</p> <h3>2023 Trends:</h3> <p><strong>1.Open-source LLMs</strong></p> <p>The release of <a href="https://arxiv.org/pdf/2307.09288.pdf" rel="external nofollow noopener" target="_blank">Llama 2</a> for research and commercial use is probably a defining moment in 2023 because in my opinion it not only started a culture of open sourcing high quality LLM without commercial limitation — the open culture that is quite deep rooted in AI research community, but also it has shown a belief to researchers that open source models can be at par with closed source models.</p> <p>Of course HuggingFace has always been a driving force behind to make sure any new model or new data is accessible.</p> <p><strong>2.Smaller Model Thanks to Quality Data</strong></p> <p><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" rel="external nofollow noopener" target="_blank">Alpaca-7B</a> demonstrated that with 52k high-quality alignment data and <a href="https://arxiv.org/pdf/2302.13971.pdf" rel="external nofollow noopener" target="_blank">LLama-7B</a> model, it is able to train a model that behaves similarly with GPT3 text-davinci-003.</p> <p><a href="https://arxiv.org/pdf/2305.11206.pdf" rel="external nofollow noopener" target="_blank">Less is More</a> showed that you do not need that much data to do alignment. 1,000 carefully curated prompts and responses are good enough.</p> <p><a href="https://arxiv.org/pdf/2306.11644.pdf" rel="external nofollow noopener" target="_blank">Textbooks are All You Need</a> trained small models from scatch with textbook quality data, and synthetically generated textbook. <a href="https://huggingface.co/microsoft/phi-2" rel="external nofollow noopener" target="_blank">phi-2</a> shows SOTA performance among model ≤ 13 B.</p> <p><a href="https://arxiv.org/pdf/2306.02707.pdf" rel="external nofollow noopener" target="_blank">Orca</a> demonstrated that small language model can have better reasoning by imitating the reasoning process of larger LM.</p> <p>The drop of <a href="https://mistral.ai/news/announcing-mistral-7b/" rel="external nofollow noopener" target="_blank">Mistral 7B</a> was a big thing in the open source community because at the time of release, it was the best. <a href="https://mistral.ai/news/mixtral-of-experts/" rel="external nofollow noopener" target="_blank">Mixtral</a> is the first time that open source model can match and even outperform GPT-3.5, with a sparse mixture-of-expert network.</p> <p><strong>3.AI Feedback Instead of Human Feedback</strong></p> <p><a href="https://www.pnas.org/doi/10.1073/pnas.2305016120" rel="external nofollow noopener" target="_blank">ChatGPT outperforms crowd workers for text-annotation tasks</a> has shown that ChatGPT has demonstrated the potential of leveraging AI feedback without compromise of quality.</p> <p>It is not surprising to replace human feedback with AI feedback, once an aligned and good enough model exists as human feedback is expensive, and not scalable, and sometimes is wrong due to various factors like emotion, boredom, etc.</p> <p><a href="https://arxiv.org/pdf/2310.16944.pdf" rel="external nofollow noopener" target="_blank">Zephyr-7B</a> surpassed LLama2-Chat-70B. In particularly, it uses GPT-4 preference to rank the synthetic response data, which is later on used for <a href="https://arxiv.org/pdf/2305.18290.pdf" rel="external nofollow noopener" target="_blank">Direct Preference Optimisation</a>.</p> <p><strong>4. Synthetic Data</strong></p> <p>With better and better language model, synthetic data generated by LLM starts making sense.</p> <p><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" rel="external nofollow noopener" target="_blank">Alpaca-7B</a> leveraged language model to generate instruction data with <a href="https://arxiv.org/pdf/2212.10560.pdf" rel="external nofollow noopener" target="_blank">Self-Instruct</a>.</p> <p><a href="https://arxiv.org/pdf/2304.12244.pdf" rel="external nofollow noopener" target="_blank">WizardLM</a> introduced instruction evolution to turn an initial instruction into more complex instruction. It found that it outperforms ChatGPT when instruction is more complex.</p> <p><strong>5.Attempt to Lengthen Context Window</strong></p> <p>Long context window is important not only because it can cater more real life use case like understanding a long document, but also it enables model to solve problem that is very complex which requires long term reasoning.</p> <p><a href="https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/" rel="external nofollow noopener" target="_blank">NTK-Aware Scaled RoPE</a> introduced neural tangent theory (NTK) to interpolate RoPE Fourier space. Without finetuning, it’s able to achieve low perplexity in extended context window beyond training by only changing 3 lines of code</p> <p><a href="https://arxiv.org/pdf/2309.17453.pdf" rel="external nofollow noopener" target="_blank">StreamingLLM</a> allowed a model trained with limited context window to inference on infinite sequence length by leveraging the finding that keeping the hidden states (KV) of initial tokens can recover most performance.</p> <p><a href="https://arxiv.org/pdf/2307.03172.pdf" rel="external nofollow noopener" target="_blank">Lost in the Middle</a> showed that performance degrades in the middle of long context.</p> <p><a href="https://www.anthropic.com/index/claude-2-1-prompting" rel="external nofollow noopener" target="_blank">Long context prompting</a> increased long term recall significantly by adding “<em>Here is the most relevant sentence in the context:”. </em>Yet, this testing is not extended to other models because it is not a research paper.</p> <p><strong>6.Multimodel LLM</strong></p> <p>A lot of our daily use cases that needs visual cues can be empowered. It basically completes a personal assistant. GPT-4-V and open sourced <a href="https://arxiv.org/pdf/2304.08485.pdf" rel="external nofollow noopener" target="_blank">LLava</a> are great examples.</p> <p><strong>7.Prompt Engineering</strong></p> <p>There are quite a lot of research papers in prompt engineering.</p> <p><a href="https://arxiv.org/pdf/2305.10601.pdf" rel="external nofollow noopener" target="_blank">Tree of Thoughts</a> is the one that generalises Chain of Thoughts approach by allowing LLM to consider different reasoning paths towards the same problem. It can be further elevated to Monte Carlo tree search, which empowered <a href="https://www.nature.com/articles/nature16961" rel="external nofollow noopener" target="_blank">AlphaGo</a> to defeat human champion by 5 games to 0.</p> <p><a href="https://arxiv.org/pdf/2210.03629.pdf" rel="external nofollow noopener" target="_blank">ReAct prompting</a> is to add action on top of thoughts/ reasons so that a LLM does not limit itself to its own representation. It can interact with the external world for accurate and updated information.</p> <p><a href="https://arxiv.org/pdf/2302.04761.pdf" rel="external nofollow noopener" target="_blank">Toolformer</a> is an approach to explicitly teach language model to use tools like APIs or a calculator.</p> <p>With action added, it turns an LLM into an autonomous agent.</p> <p><strong>8.Quantised/ optimisation for training</strong></p> <p>This is a last but not least point.</p> <p>From float32 to bfloat16, <a href="https://huggingface.co/blog/4bit-transformers-bitsandbytes" rel="external nofollow noopener" target="_blank">to 8-bit, to 4-bit</a>; from LoRa to <a href="https://arxiv.org/pdf/2305.14314.pdf" rel="external nofollow noopener" target="_blank">QLoRA</a>. It not just reduces GPU RAM requirement, but also training time. It empowers talented people without rich GPU access to perform proof of concept and research, so that the open source community continues to thrive.</p> <p>In short, rather than saying 2023 is The Year of LLM, I would say 2023 is The Year of <strong>Open Source</strong> LLM. LLM has become a commodity, and become accessible by people who are willing to learn. Having said that, using them in production still remains challenging because:</p> <ul> <li>the no. of use case in this world is almost unlimited</li> <li>100% correctness of LLM output still remains an open question</li> <li>limited supply of high end GPU.</li> </ul> <h3><strong>2024 Trends:</strong></h3> <p><strong>1.Small Language model (SLM, &lt;=2B)</strong></p> <p>I think deep learning has come to an era that everyone starts realising quality data is important, just like traditional machine learning. Quality data reduces conflicting learning objective, avoid local minimum and encourages faster convergence.</p> <p>The problems are:</p> <ul> <li>what is “quality” data? Diverse and correct with sufficient reasoning and different complexities?</li> <li>how to execute it at scale?</li> </ul> <p>Out of the trillion tokens, how much is actually useful? If only 5% is useful, a much smaller model is possible to “compress” all training data and learn a meaningful representation. For example, <a href="https://arxiv.org/pdf/2306.11644.pdf" rel="external nofollow noopener" target="_blank">phi-1</a> model is only trained on 7B tokens, while <a href="https://arxiv.org/pdf/2307.09288.pdf" rel="external nofollow noopener" target="_blank">Llama2</a> is trained on 2T tokens.</p> <p>The secret recipe to a good LLM is the underlying data. As you can notice, everyone releases their model, but not everyone releases their training data.</p> <p><strong>2.Synthetic data</strong></p> <p>It is an inevitable route. There are 3 variables to a model (Dataset Size, Model Size, Compute) that determines a model’s power. Given the fixed amount compute, you can trade off between model size and data size. But what if you don’t have unlimited compute? You can always scale up a model, but not data.</p> <p>If the world does not contain enough high quality data, what can one do?</p> <p>Generate.</p> <p>If the world does not contain intelligent enough data to learn from to achieve superintelligence, what can one do?</p> <p>Generate.</p> <p>It makes sense to generate if you have a powerful LLM with verifiers.</p> <p><strong>3.Industry Specific Dataset &amp; Benchmark</strong></p> <p>The internet does not have all the data in this universe after all.</p> <p>Number of use case in this planet is a long tail distribution.</p> <p>Opportunity goes back to industry players who have a moat — private data that they could capitalise. There is no better time than now to create business value by digitalising physical document.</p> <p>One model to rule them all? Nah, centralised LLM will become decentralised and tailored to specific use cases.</p> <p><strong>4.LLM as a Search Engine</strong></p> <p>Before LLM, search engine can only search what already exists; now LLM can search for something that does not exist yet. It completely changes the universe of search space from limited to unlimited.</p> <p>Searching with LLM becomes meaningful if latency drastically decreases because one can simulate more given the same time. <a href="https://www.nature.com/articles/s41586-023-06924-6" rel="external nofollow noopener" target="_blank">FunSearch</a> searches for how to solve a problem by combining genetic algorithm and language model which is used as a solution generator and as an evaluator.</p> <p>Search becomes scalable with small language model, and quantitative change leads to qualitative change.</p> <p><strong>5.Reasoning Engine in Robotics</strong></p> <p>With smaller model, latency becomes low enough such that robot can act and react in real time, and it becomes possible to deploy LLM in edge device, so robot can run in an offline manner. Numerous researches shows that using text-only LLM as a reasoning engine can significantly improve robotics performance, not to mention leveraging multimodal LLM.</p> <p><strong>6.The Quest for AGI and Superintelligence Continues</strong></p> <p>It depends on the definition of AGI or superintelligence. Let’s define it as an intelligent agent who surpasses the intelligence of the most gifted human being.</p> <p>Crystalized from the past trends, there are few possible paths that will inevitably happen in my opinion:</p> <ul> <li>Quantity : can 100 gifted minds imitated by language model surpass the most gifted human minds? It is not impossible if you view problem as considering all possible reasoning paths like Monte Carlo Tree Search and pick the weight adjusted choice.</li> <li>Quality: can we generate data more intelligent than the original data that the generator was trained from? <a href="https://arxiv.org/pdf/2304.12244.pdf" rel="external nofollow noopener" target="_blank">WizardLM</a> is a good showcase that the difficulty of instruction be increased by LLM. LLM behaves like an approximate retrieval system because of its autoregressive nature so it might fail reasoning test if training data does not have so. Can we generate data that is not in training set of the generator model?</li> </ul> <p>Quantity is possibly an easier path forward. After such system exists, the training signal can be distilled by another language model.</p> <p>In both cases, there exists a limit in the verification/ falsifiability of knowledge that that there is no LLM which can validate the generated solution. There is an exception through: a set of problems can be quickly checkable but not quickly solvable (in NP but not in P). They will become the new testbed for LLM.</p> <p>What about knowledge that is not quickly checkable? Maybe in some day LLM can prove P=NP or the vice versa.</p> <p>So, will superintelligence arrive at 2024? I don’t know, but the stage is set and it’s just a matter of time. For most people, it’s game changing enough when LLM can match the intelligence of an average person, and you can have multiple of them working for you.</p> <p><strong>What do you think? What’s waiting us in 2024?</strong></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=cbd5211cf49b" width="1" height="1" alt=""></p> </body></html>